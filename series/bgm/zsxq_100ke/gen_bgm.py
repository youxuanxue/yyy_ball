"""
æ—¥æ—¥ç”Ÿé‡‘ (zsxq_100ke) ç³»åˆ— BGM ç”Ÿæˆè„šæœ¬

ä½¿ç”¨ MusicGen æ¨¡å‹åœ¨æœ¬åœ°ç”Ÿæˆé€‚åˆå›½æ°‘ç†è´¢ç§‘æ™®åŠ¨ç”»çš„èƒŒæ™¯éŸ³ä¹ã€‚
éŸ³ä¹é£æ ¼ï¼šä¸“ä¸šä½†æ¥åœ°æ°”ã€ç§¯æå‘ä¸Šã€è½»æ¾æ˜å¿«ï¼Œé€‚åˆå¾ªç¯æ’­æ”¾ã€‚
"""

import os
import sys
import torch
import scipy
from datetime import datetime

# å°†é¡¹ç›®æ ¹ç›®å½•åŠ å…¥ path
sys.path.append(os.path.abspath(os.path.join(os.path.dirname(__file__), "../../..")))

try:
    from transformers import pipeline
except ImportError:
    print("è¯·å…ˆå®‰è£… transformers: uv add transformers torch scipy")
    sys.exit(1)

# ================= é…ç½®åŒº =================

# å¯é€‰æ¨¡å‹: 'facebook/musicgen-small', 'facebook/musicgen-medium', 'facebook/musicgen-large'
# M4 16GB æ¨è: 'facebook/musicgen-small' (æœ€å¿«) æˆ– 'facebook/musicgen-medium'
MODEL_NAME = 'facebook/musicgen-small'

# è¾“å‡ºç›®å½•ï¼ˆå½“å‰ç›®å½•ï¼‰
OUTPUT_DIR = os.path.dirname(os.path.abspath(__file__))

# ç”Ÿæˆæ—¶é•¿æ§åˆ¶
# MusicGen çº¦ 50 tokens/ç§’
# 30ç§’è¶³å¤Ÿä½œä¸ºå¾ªç¯BGMä½¿ç”¨
DURATION_SECONDS = 30
MAX_NEW_TOKENS = int(DURATION_SECONDS * 51.2)

# ã€Œæ—¥æ—¥ç”Ÿé‡‘ã€ç³»åˆ— BGM é£æ ¼å®šä¹‰
# ç‰¹ç‚¹ï¼šä¸“ä¸šã€ç§¯æã€è½»æ¾ã€é€‚åˆå¾ªç¯ã€ä¸æ²‰é—·
STYLES = {
    # é£æ ¼1: ä¸“ä¸šå‹å¥½ - é€‚åˆçŸ¥è¯†è®²è§£éƒ¨åˆ†
    "professional_friendly": [
        "Background music for finance education video, "
        "light corporate, positive, friendly tone, "
        "soft synth pads, gentle piano, subtle electronic beat, "
        "clean production, medium tempo 100-110 bpm, "
        "professional but approachable, loopable, no vocals"
    ],
    
    # é£æ ¼2: ç§¯æå¢é•¿ - é€‚åˆç­–ç•¥å»ºè®®ã€è¡ŒåŠ¨å·å¬éƒ¨åˆ†
    "positive_growth": [
        "Uplifting background music for investment education, "
        "inspiring, optimistic, motivational, "
        "bright piano melody, light orchestral strings, "
        "subtle percussion, building energy, "
        "modern corporate feel, 105-115 bpm, loopable, no vocals"
    ],
    
    # é£æ ¼3: è½»æ¾æ€è€ƒ - é€‚åˆæ¦‚å¿µè§£é‡Šã€å‰–æéƒ¨åˆ†
    "thinking_light": [
        "Light thinking music for educational content, "
        "curious, intellectual but friendly, "
        "pizzicato strings, soft marimba, gentle bells, "
        "minimal electronic elements, clean mix, "
        "90-100 bpm, seamless loop friendly, no vocals"
    ],
    
    # é£æ ¼4: æ¸©æš–é™ªä¼´ - é€‚åˆç—›ç‚¹å…±é¸£ã€åœºæ™¯æè¿°éƒ¨åˆ†
    "warm_companion": [
        "Warm background music for lifestyle finance video, "
        "comforting, empathetic, gentle, "
        "acoustic guitar arpeggios, soft piano, light strings, "
        "intimate feel, like a friend talking, "
        "85-95 bpm, loopable, no vocals"
    ]
}

# =========================================


def generate_zsxq_bgm(styles_to_generate=None):
    """
    ç”Ÿæˆã€Œæ—¥æ—¥ç”Ÿé‡‘ã€ç³»åˆ—ä¸“ç”¨ BGM
    
    Args:
        styles_to_generate: è¦ç”Ÿæˆçš„é£æ ¼åˆ—è¡¨ï¼Œé»˜è®¤ç”Ÿæˆæ‰€æœ‰é£æ ¼
    """
    print("ğŸµ ã€Œæ—¥æ—¥ç”Ÿé‡‘ã€BGM ç”Ÿæˆå™¨")
    print("=" * 50)
    
    # æ£€æŸ¥ç¡¬ä»¶ç¯å¢ƒ
    print("ğŸ–¥ï¸  æ­£åœ¨æ£€æŸ¥ç¡¬ä»¶ç¯å¢ƒ...")
    
    if torch.backends.mps.is_available():
        device = "mps"
        print("ğŸš€ æ£€æµ‹åˆ° Apple Silicon (MPS) åŠ é€Ÿå¼€å¯")
    elif torch.cuda.is_available():
        device = "cuda"
        print("ğŸš€ æ£€æµ‹åˆ° NVIDIA GPU (CUDA) åŠ é€Ÿå¼€å¯")
    else:
        device = "cpu"
        print("ğŸ¢ æœªæ£€æµ‹åˆ° GPUï¼Œä½¿ç”¨ CPU è¿è¡Œ (ä¼šæ¯”è¾ƒæ…¢)")
    
    # ç¡®ä¿è¾“å‡ºç›®å½•å­˜åœ¨
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
    
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {OUTPUT_DIR}")
    print(f"â³ æ­£åœ¨åŠ è½½æ¨¡å‹: {MODEL_NAME} (ç¬¬ä¸€æ¬¡è¿è¡Œä¼šä¸‹è½½çº¦ 1-2GB)...")
    
    # åˆå§‹åŒ– Pipeline
    try:
        synthesiser = pipeline("text-to-audio", model=MODEL_NAME, device=device)
    except Exception as e:
        print(f"âš ï¸  åŠ è½½è®¾å¤‡ {device} å¤±è´¥ï¼Œå°è¯•åˆ‡æ¢å› CPU... ({e})")
        synthesiser = pipeline("text-to-audio", model=MODEL_NAME, device="cpu")
    
    # ç¡®å®šè¦ç”Ÿæˆçš„é£æ ¼
    if styles_to_generate is None:
        styles_to_generate = list(STYLES.keys())
    
    print(f"\nğŸ¹ å¼€å§‹ç”Ÿæˆï¼Œå…± {len(styles_to_generate)} ç§é£æ ¼...")
    print(f"â±ï¸  æ¯ä¸ªé£æ ¼ç”Ÿæˆæ—¶é•¿: {DURATION_SECONDS} ç§’")
    print("=" * 50)
    
    generated_files = []
    
    for style_name in styles_to_generate:
        if style_name not in STYLES:
            print(f"âš ï¸  æœªçŸ¥é£æ ¼: {style_name}ï¼Œè·³è¿‡...")
            continue
            
        prompts = STYLES[style_name]
        
        for i, prompt in enumerate(prompts):
            print(f"\nğŸ¼ æ­£åœ¨ç”Ÿæˆé£æ ¼: [{style_name}] ({i+1}/{len(prompts)})")
            print(f"   Prompt: {prompt[:60]}...")
            
            try:
                # ç”ŸæˆéŸ³ä¹
                music = synthesiser(
                    prompt,
                    forward_params={
                        "max_new_tokens": MAX_NEW_TOKENS,
                        "do_sample": True
                    }
                )
                
                # å¤„ç†éŸ³é¢‘æ•°æ®
                audio_data = music['audio'][0]
                if audio_data.ndim == 2 and audio_data.shape[0] == 1:
                    audio_data = audio_data.squeeze(0)
                    
                sample_rate = music['sampling_rate']
                
                # ä¿å­˜æ–‡ä»¶
                timestamp = datetime.now().strftime('%Y%m%d_%H%M')
                filename = f"bgm_{style_name}_{timestamp}.wav"
                filepath = os.path.join(OUTPUT_DIR, filename)
                
                scipy.io.wavfile.write(filepath, rate=sample_rate, data=audio_data)
                print(f"   âœ… å·²ä¿å­˜: {filename}")
                generated_files.append(filepath)
                
            except Exception as e:
                print(f"   âŒ ç”Ÿæˆå¤±è´¥: {e}")
    
    print("\n" + "=" * 50)
    print(f"ğŸ‰ ç”Ÿæˆå®Œæˆï¼å…±ç”Ÿæˆ {len(generated_files)} ä¸ªæ–‡ä»¶")
    print(f"ğŸ“‚ æ–‡ä»¶ä½ç½®: {OUTPUT_DIR}")
    print("\nğŸ’¡ ä½¿ç”¨å»ºè®®:")
    print("   - professional_friendly: é€‚åˆçŸ¥è¯†è®²è§£åœºæ™¯")
    print("   - positive_growth: é€‚åˆç­–ç•¥å»ºè®®ã€è¡ŒåŠ¨å·å¬")
    print("   - thinking_light: é€‚åˆæ¦‚å¿µè§£é‡Šã€å‰–æéƒ¨åˆ†")
    print("   - warm_companion: é€‚åˆç—›ç‚¹å…±é¸£ã€åœºæ™¯æè¿°")
    
    return generated_files


def generate_single_style(style_name):
    """
    ç”Ÿæˆå•ä¸ªé£æ ¼çš„ BGM
    
    Args:
        style_name: é£æ ¼åç§°
    """
    if style_name not in STYLES:
        print(f"âŒ æœªçŸ¥é£æ ¼: {style_name}")
        print(f"ğŸ’¡ å¯ç”¨é£æ ¼: {', '.join(STYLES.keys())}")
        return []
    
    return generate_zsxq_bgm(styles_to_generate=[style_name])


def list_styles():
    """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ BGM é£æ ¼"""
    print("ğŸµ ã€Œæ—¥æ—¥ç”Ÿé‡‘ã€å¯ç”¨ BGM é£æ ¼:")
    print("=" * 50)
    for name, prompts in STYLES.items():
        print(f"\nğŸ“Œ {name}:")
        for prompt in prompts:
            # æ˜¾ç¤ºå‰100ä¸ªå­—ç¬¦
            print(f"   {prompt[:100]}...")


if __name__ == "__main__":
    import argparse
    
    parser = argparse.ArgumentParser(description="æ—¥æ—¥ç”Ÿé‡‘ BGM ç”Ÿæˆå™¨")
    parser.add_argument(
        "--style", 
        type=str, 
        default=None,
        help=f"æŒ‡å®šè¦ç”Ÿæˆçš„é£æ ¼ ({', '.join(STYLES.keys())})"
    )
    parser.add_argument(
        "--list", 
        action="store_true",
        help="åˆ—å‡ºæ‰€æœ‰å¯ç”¨é£æ ¼"
    )
    parser.add_argument(
        "--all",
        action="store_true",
        help="ç”Ÿæˆæ‰€æœ‰é£æ ¼ï¼ˆé»˜è®¤è¡Œä¸ºï¼‰"
    )
    
    args = parser.parse_args()
    
    if args.list:
        list_styles()
    elif args.style:
        generate_single_style(args.style)
    else:
        # é»˜è®¤åªç”Ÿæˆä¸€ä¸ªæ¨èé£æ ¼ï¼ˆprofessional_friendlyï¼‰ï¼Œé¿å…ç”Ÿæˆå¤ªå¤š
        print("ğŸ’¡ é»˜è®¤ç”Ÿæˆæ¨èé£æ ¼: professional_friendly")
        print("   ä½¿ç”¨ --all ç”Ÿæˆæ‰€æœ‰é£æ ¼ï¼Œæˆ– --style <é£æ ¼å> æŒ‡å®šé£æ ¼")
        print()
        generate_single_style("professional_friendly")
