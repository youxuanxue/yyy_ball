"""
Edge TTS è¯­éŸ³ç”Ÿæˆæ¨¡å—

æä¾›ä½¿ç”¨ Edge TTS ç”Ÿæˆä¸­æ–‡è¯­éŸ³çš„åŠŸèƒ½ã€‚
"""
import asyncio
import edge_tts
import os
import json


def parse_json_script(file_path):
    """
    è§£æ JSON è„šæœ¬ï¼Œæå–å£æ’­å†…å®¹ã€‚
    è¿”å›å­—å…¸: { "scene_index_key": "voiceover_script_content" }
    
    Args:
        file_path: JSON è„šæœ¬æ–‡ä»¶è·¯å¾„
    
    Returns:
        dict: åœºæ™¯ç´¢å¼•åˆ°å£æ’­è„šæœ¬çš„æ˜ å°„
    """
    with open(file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)
    
    scripts = {}
    
    # éå† scenes åˆ—è¡¨
    for scene in data.get("scenes", []):
        # è·å– scene_index å’Œ voiceover_script
        idx = scene.get("scene_index")
        script = scene.get("voiceover_script")
            
        if idx is not None and script:
            scripts[str(idx)] = script
                
    return scripts


# ============================================================================
# Edge TTS ä¸­æ–‡è¯­éŸ³é€‰é¡¹è¯´æ˜
# ============================================================================
"""
Edge TTS æ”¯æŒçš„ä¸­æ–‡è¯­éŸ³é€‰é¡¹åŠå…¶ç‰¹ç‚¹ï¼š

ã€ä¸­å›½å¤§é™†æ™®é€šè¯ - zh-CNã€‘
å¥³æ€§è¯­éŸ³ï¼š
  - zh-CN-XiaoxiaoNeural (æ™“æ™“) â­ é»˜è®¤æ¨è
    éŸ³è‰²ï¼šå¹´è½»å¥³æ€§ï¼Œç”œç¾æ´»æ³¼ï¼Œé€‚åˆå„¿ç«¥æ•™è‚²ã€è½»æ¾å†…å®¹
    é€‚ç”¨ï¼šå„¿ç«¥æ•™è‚²ã€æ•…äº‹è®²è¿°ã€è½»æ¾è§†é¢‘
  
  - zh-CN-XiaoyiNeural (æ™“ä¼Š)
    éŸ³è‰²ï¼šæˆç†Ÿå¥³æ€§ï¼Œæ¸©å’Œäº²åˆ‡ï¼Œé€‚åˆæ­£å¼åœºåˆ
    é€‚ç”¨ï¼šæ•™è‚²è¯¾ç¨‹ã€å®¢æœã€æ–°é—»æ’­æŠ¥

ç”·æ€§è¯­éŸ³ï¼š
  - zh-CN-YunxiNeural (äº‘å¸Œ) â­ æ¨è
    éŸ³è‰²ï¼šå¹´è½»ç”·æ€§ï¼Œæ¸…æ™°è‡ªç„¶ï¼Œäº²å’ŒåŠ›å¼º
    é€‚ç”¨ï¼šæ•™è‚²è§†é¢‘ã€çŸ¥è¯†ç§‘æ™®ã€æ—¥å¸¸å¯¹è¯
  
  - zh-CN-YunjianNeural (äº‘å¥)
    éŸ³è‰²ï¼šæˆç†Ÿç”·æ€§ï¼Œæ²‰ç¨³ä¸“ä¸šï¼Œæƒå¨æ„Ÿå¼º
    é€‚ç”¨ï¼šå•†åŠ¡æ¼”è®²ã€æ–°é—»æ’­æŠ¥ã€æ­£å¼æ–‡æ¡£
  
  - zh-CN-YunxiaNeural (äº‘å¤)
    éŸ³è‰²ï¼šæˆç†Ÿç”·æ€§ï¼Œæ¸©æš–äº²åˆ‡ï¼Œè¯­é€Ÿè¾ƒæ…¢
    é€‚ç”¨ï¼šæ•…äº‹æœ—è¯»ã€æƒ…æ„Ÿå†…å®¹ã€æ·±åº¦å†…å®¹
  
  - zh-CN-YunyangNeural (äº‘æ‰¬)
    éŸ³è‰²ï¼šå¹´è½»ç”·æ€§ï¼Œæ˜äº®æœ‰æ´»åŠ›ï¼ŒèŠ‚å¥æ„Ÿå¼º
    é€‚ç”¨ï¼šæ¸¸æˆè§£è¯´ã€è¿åŠ¨è§†é¢‘ã€å¨±ä¹å†…å®¹

ã€é¦™æ¸¯ç²¤è¯­ - zh-HKã€‘
  - zh-HK-HiuGaaiNeural (æ™“ä½³) - å¹´è½»å¥³æ€§
  - zh-HK-HiuMaanNeural (æ™“æ–‡) - æˆç†Ÿå¥³æ€§
  - zh-HK-WanLungNeural (äº‘é¾™) - æˆç†Ÿç”·æ€§

ã€å°æ¹¾å›½è¯­ - zh-TWã€‘
  - zh-TW-HsiaoChenNeural (æ™“è¾°) - å¹´è½»å¥³æ€§
  - zh-TW-HsiaoYuNeural (æ™“è¯­) - æˆç†Ÿå¥³æ€§
  - zh-TW-YunJheNeural (äº‘å“²) - æˆç†Ÿç”·æ€§

ã€æ–¹è¨€è¯­éŸ³ã€‘
  - zh-CN-liaoning-XiaobeiNeural (æ™“åŒ—) - ä¸œåŒ—è¯ï¼Œå¹´è½»å¥³æ€§
  - zh-CN-shaanxi-XiaoniNeural (æ™“å¦®) - é™•è¥¿è¯ï¼Œå¹´è½»å¥³æ€§

è¯¦ç»†æ–‡æ¡£è¯·å‚è€ƒ: docs/edge_tts_voices_guide.md
"""


async def list_chinese_voices():
    """
    åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„ä¸­æ–‡è¯­éŸ³é€‰é¡¹
    
    Returns:
        dict: æŒ‰åœ°åŒºåˆ†ç±»çš„è¯­éŸ³åˆ—è¡¨
    """
    voices = await edge_tts.list_voices()
    chinese_voices = {
        'zh-CN': [],
        'zh-HK': [],
        'zh-TW': [],
        'dialects': []
    }
    
    for voice in voices:
        locale = voice.get('Locale', '')
        short_name = voice.get('ShortName', '')
        friendly_name = voice.get('FriendlyName', '')
        gender = voice.get('Gender', '')
        
        if locale.startswith('zh-CN') and 'liaoning' not in locale and 'shaanxi' not in locale:
            chinese_voices['zh-CN'].append({
                'short_name': short_name,
                'friendly_name': friendly_name,
                'gender': gender
            })
        elif locale.startswith('zh-HK'):
            chinese_voices['zh-HK'].append({
                'short_name': short_name,
                'friendly_name': friendly_name,
                'gender': gender
            })
        elif locale.startswith('zh-TW'):
            chinese_voices['zh-TW'].append({
                'short_name': short_name,
                'friendly_name': friendly_name,
                'gender': gender
            })
        elif 'liaoning' in locale or 'shaanxi' in locale:
            chinese_voices['dialects'].append({
                'short_name': short_name,
                'friendly_name': friendly_name,
                'gender': gender
            })
    
    return chinese_voices


def print_voice_options():
    """æ‰“å°æ‰€æœ‰å¯ç”¨çš„ä¸­æ–‡è¯­éŸ³é€‰é¡¹"""
    print("\n" + "=" * 80)
    print("ğŸ™ï¸ Edge TTS ä¸­æ–‡è¯­éŸ³é€‰é¡¹")
    print("=" * 80)
    
    voices = asyncio.run(list_chinese_voices())
    
    print("\nã€ä¸­å›½å¤§é™†æ™®é€šè¯ - zh-CNã€‘")
    for voice in voices['zh-CN']:
        gender_emoji = "ğŸ‘¨" if voice['gender'] == 'Male' else "ğŸ‘©"
        print(f"  {gender_emoji} {voice['short_name']:30s} - {voice['friendly_name']}")
    
    if voices['zh-HK']:
        print("\nã€é¦™æ¸¯ç²¤è¯­ - zh-HKã€‘")
        for voice in voices['zh-HK']:
            gender_emoji = "ğŸ‘¨" if voice['gender'] == 'Male' else "ğŸ‘©"
            print(f"  {gender_emoji} {voice['short_name']:30s} - {voice['friendly_name']}")
    
    if voices['zh-TW']:
        print("\nã€å°æ¹¾å›½è¯­ - zh-TWã€‘")
        for voice in voices['zh-TW']:
            gender_emoji = "ğŸ‘¨" if voice['gender'] == 'Male' else "ğŸ‘©"
            print(f"  {gender_emoji} {voice['short_name']:30s} - {voice['friendly_name']}")
    
    if voices['dialects']:
        print("\nã€æ–¹è¨€è¯­éŸ³ã€‘")
        for voice in voices['dialects']:
            gender_emoji = "ğŸ‘¨" if voice['gender'] == 'Male' else "ğŸ‘©"
            print(f"  {gender_emoji} {voice['short_name']:30s} - {voice['friendly_name']}")
    
    print("\n" + "=" * 80)
    print("ğŸ’¡ æç¤º: è¯¦ç»†è¯­éŸ³ç‰¹ç‚¹å’Œä½¿ç”¨å»ºè®®è¯·å‚è€ƒ docs/edge_tts_voices_guide.md")
    print("=" * 80 + "\n")


async def list_all_voices():
    """è·å–æ‰€æœ‰å¯ç”¨çš„è¯­éŸ³åˆ—è¡¨"""
    return await edge_tts.list_voices()


def list_all_voices_sync():
    """åŒæ­¥ç‰ˆæœ¬ï¼šè·å–æ‰€æœ‰å¯ç”¨çš„è¯­éŸ³åˆ—è¡¨"""
    return asyncio.run(list_all_voices())


def categorize_voices(voices):
    """æŒ‰è¯­è¨€å’Œåœ°åŒºåˆ†ç±»è¯­éŸ³"""
    from collections import defaultdict
    categorized = defaultdict(list)
    
    for voice in voices:
        locale = voice.get('Locale', '')
        gender = voice.get('Gender', '')
        name = voice.get('Name', '')
        short_name = voice.get('ShortName', '')
        friendly_name = voice.get('FriendlyName', '')
        
        categorized[locale].append({
            'name': name,
            'short_name': short_name,
            'friendly_name': friendly_name,
            'gender': gender,
            'locale': locale,
            'voice_type': voice.get('VoiceType', ''),
            'status': voice.get('Status', ''),
        })
    
    return categorized


async def generate_voice_for_scripts(scripts_dict, output_dir, voice="zh-CN-XiaoxiaoNeural"):
    """
    æ ¹æ®è„šæœ¬å­—å…¸ç”Ÿæˆ MP3 éŸ³é¢‘ã€‚
    
    Args:
        scripts_dict (dict): { "filename_key": "text_content" }
        output_dir (str): è¾“å‡ºç›®å½•è·¯å¾„
        voice (str): Edge TTS è¯­éŸ³æ¨¡å‹ï¼Œé»˜è®¤ä¸º "zh-CN-XiaoxiaoNeural" (æ™“æ™“)
                    å¸¸ç”¨é€‰é¡¹ï¼š
                    - zh-CN-XiaoxiaoNeural: å¹´è½»å¥³æ€§ï¼Œæ´»æ³¼ç”œç¾ï¼Œé€‚åˆå„¿ç«¥æ•™è‚² â­
                    - zh-CN-XiaoyiNeural: æˆç†Ÿå¥³æ€§ï¼Œæ¸©å’Œäº²åˆ‡ï¼Œé€‚åˆæ•™è‚²è¯¾ç¨‹
                    - zh-CN-YunxiNeural: å¹´è½»ç”·æ€§ï¼Œæ¸…æ™°è‡ªç„¶ï¼Œé€‚åˆçŸ¥è¯†ç§‘æ™® â­
                    - zh-CN-YunjianNeural: æˆç†Ÿç”·æ€§ï¼Œæ²‰ç¨³ä¸“ä¸šï¼Œé€‚åˆæ­£å¼åœºåˆ
                    - zh-CN-YunxiaNeural: æˆç†Ÿç”·æ€§ï¼Œæ¸©æš–äº²åˆ‡ï¼Œé€‚åˆæ•…äº‹è®²è¿°
                    - zh-CN-YunyangNeural: å¹´è½»ç”·æ€§ï¼Œæœ‰æ´»åŠ›ï¼Œé€‚åˆå¨±ä¹å†…å®¹
                    æ›´å¤šé€‰é¡¹è¯·å‚è€ƒæ–‡ä»¶é¡¶éƒ¨çš„æ³¨é‡Šæˆ–è¿è¡Œ print_voice_options()
    """
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)
        
    print(f"ğŸ™ï¸ æ­£åœ¨ç”Ÿæˆè¯­éŸ³ (Voice: {voice})...")
    print(f"ğŸ“‚ è¾“å‡ºç›®å½•: {output_dir}")
    
    for key, text in scripts_dict.items():
        # è‡ªåŠ¨è¡¥å…¨ .mp3 åç¼€
        filename = key if key.endswith(".mp3") else f"{key}.mp3"
        output_file = os.path.join(output_dir, filename)
        
        # è°ƒç”¨ Edge TTS
        communicate = edge_tts.Communicate(text, voice)
        await communicate.save(output_file)
        print(f"âœ… å·²ç”Ÿæˆ: {filename}")
        
    print("\nğŸ‰ æ‰€æœ‰è¯­éŸ³ç”Ÿæˆå®Œæ¯•ï¼")


def gen_voice_clips_from_json(script_path, output_dir, voice="zh-CN-YunxiNeural"):
    """
    ä» JSON è„šæœ¬ç”Ÿæˆè¯­éŸ³çš„å…¥å£å‡½æ•°
    
    Args:
        script_path (str): JSON è„šæœ¬æ–‡ä»¶è·¯å¾„
        output_dir (str): è¾“å‡ºç›®å½•è·¯å¾„
        voice (str): Edge TTS è¯­éŸ³æ¨¡å‹ï¼Œé»˜è®¤ä¸º "zh-CN-YunxiNeural" (äº‘å¸Œ)
                    å¸¸ç”¨é€‰é¡¹ï¼š
                    - zh-CN-XiaoxiaoNeural: å¹´è½»å¥³æ€§ï¼Œæ´»æ³¼ç”œç¾ï¼Œé€‚åˆå„¿ç«¥æ•™è‚² â­
                    - zh-CN-YunxiNeural: å¹´è½»ç”·æ€§ï¼Œæ¸…æ™°è‡ªç„¶ï¼Œé€‚åˆçŸ¥è¯†ç§‘æ™® â­
                    æ›´å¤šé€‰é¡¹è¯·å‚è€ƒæ–‡ä»¶é¡¶éƒ¨çš„æ³¨é‡Šæˆ–è¿è¡Œ print_voice_options()
    """
    print(f"ğŸ“„ è§£æè„šæœ¬: {script_path}")
    scripts = parse_json_script(script_path)
    
    if not scripts:
        print("âš ï¸ æœªæ‰¾åˆ°ä»»ä½•å£æ’­å†…å®¹ï¼Œè¯·æ£€æŸ¥ JSON æ ¼å¼")
        return
        
    asyncio.run(generate_voice_for_scripts(scripts, output_dir, voice))

